{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a737af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Using cached dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Requirement already satisfied: python-dotenv in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from dotenv) (1.0.1)\n",
      "Using cached dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Installing collected packages: dotenv\n",
      "Successfully installed dotenv-0.9.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "990ef628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (0.3.2)\n",
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-generativeai) (2.25.1)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.175.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-generativeai) (4.25.8)\n",
      "Requirement already satisfied: pydantic in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-generativeai) (4.14.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.4)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Using cached uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Using cached google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Downloading google_api_python_client-2.175.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, httplib2, google-auth-httplib2, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\u001b[2K  Attempting uninstall: google-ai-generativelanguage‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/7\u001b[0m [google-api-python-client]\n",
      "\u001b[2K    Found existing installation: google-ai-generativelanguage 0.4.0\u001b[32m4/7\u001b[0m [google-api-python-client]\n",
      "\u001b[2K    Uninstalling google-ai-generativelanguage-0.4.0:90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/7\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K      Successfully uninstalled google-ai-generativelanguage-0.4.0m \u001b[32m5/7\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K  Attempting uninstall: google-generativeai1m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/7\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K    Found existing installation: google-generativeai 0.3.2‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/7\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K    Uninstalling google-generativeai-0.3.2:[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/7\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K      Successfully uninstalled google-generativeai-0.3.2\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6/7\u001b[0m [google-generativeai]uage]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/7\u001b[0m [google-generativeai]ogle-generativeai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed google-ai-generativelanguage-0.6.15 google-api-python-client-2.175.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 httplib2-0.22.0 pyparsing-3.2.3 uritemplate-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff5f777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fde45ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Still broken. Error:\n",
      " 404 models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))  # or paste it directly\n",
    "\n",
    "try:\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")\n",
    "    response = model.generate_content(\"Tell me a cool computer science fact.\")\n",
    "    print(\"‚úÖ API is working!\\n\")\n",
    "    print(response.text)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Still broken. Error:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2847f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyDLc6HN7FtJ_NO9mu29HgmY8WyG568q8CE\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a049cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/shaikyasin/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Retrying langchain_community.llms.google_palm.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised NotFound: 404 Requested entity was not found..\n",
      "Retrying langchain_community.llms.google_palm.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised NotFound: 404 Requested entity was not found..\n",
      "Retrying langchain_community.llms.google_palm.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised NotFound: 404 Requested entity was not found..\n",
      "Retrying langchain_community.llms.google_palm.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised NotFound: 404 Requested entity was not found..\n",
      "Retrying langchain_community.llms.google_palm.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised NotFound: 404 Requested entity was not found..\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 Requested entity was not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFound\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GooglePalm\n\u001b[32m      5\u001b[39m llm = GooglePalm()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is LangChain?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Test basic call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:148\u001b[39m, in \u001b[36mwarning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decorator to mark a function, a class, or a property as deprecated.\u001b[39;00m\n\u001b[32m     85\u001b[39m \n\u001b[32m     86\u001b[39m \u001b[33;03mWhen deprecating a classmethod, a staticmethod, or a property, the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m \u001b[33;03m            pass\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    140\u001b[39m _validate_deprecation_params(\n\u001b[32m    141\u001b[39m     removal, alternative, alternative_import, pending=pending\n\u001b[32m    142\u001b[39m )\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeprecate\u001b[39m(\n\u001b[32m    145\u001b[39m     obj: T,\n\u001b[32m    146\u001b[39m     *,\n\u001b[32m    147\u001b[39m     _obj_type: \u001b[38;5;28mstr\u001b[39m = obj_type,\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     _name: \u001b[38;5;28mstr\u001b[39m = name,\n\u001b[32m    149\u001b[39m     _message: \u001b[38;5;28mstr\u001b[39m = message,\n\u001b[32m    150\u001b[39m     _alternative: \u001b[38;5;28mstr\u001b[39m = alternative,\n\u001b[32m    151\u001b[39m     _alternative_import: \u001b[38;5;28mstr\u001b[39m = alternative_import,\n\u001b[32m    152\u001b[39m     _pending: \u001b[38;5;28mbool\u001b[39m = pending,\n\u001b[32m    153\u001b[39m     _addendum: \u001b[38;5;28mstr\u001b[39m = addendum,\n\u001b[32m    154\u001b[39m     _package: \u001b[38;5;28mstr\u001b[39m = package,\n\u001b[32m    155\u001b[39m ) -> T:\n\u001b[32m    156\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implementation of the decorator returned by `deprecated`.\"\"\"\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34memit_warning\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1086\u001b[39m, in \u001b[36m__call__\u001b[39m\u001b[34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[39m\n\u001b[32m   1072\u001b[39m         output.run = [\n\u001b[32m   1073\u001b[39m             RunInfo(run_id=run_manager.run_id) \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers\n\u001b[32m   1074\u001b[39m         ]\n\u001b[32m   1075\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magenerate\u001b[39m(\n\u001b[32m   1078\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1079\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   1080\u001b[39m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1081\u001b[39m     callbacks: Optional[Union[Callbacks, \u001b[38;5;28mlist\u001b[39m[Callbacks]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1082\u001b[39m     *,\n\u001b[32m   1083\u001b[39m     tags: Optional[Union[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1084\u001b[39m     metadata: Optional[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1085\u001b[39m     run_name: Optional[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m-> \u001b[39m\u001b[32m1086\u001b[39m     run_id: Optional[Union[uuid.UUID, \u001b[38;5;28mlist\u001b[39m[Optional[uuid.UUID]]]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1087\u001b[39m     **kwargs: Any,\n\u001b[32m   1088\u001b[39m ) -> LLMResult:\n\u001b[32m   1089\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Asynchronously pass a sequence of prompts to a model and return generations.\u001b[39;00m\n\u001b[32m   1090\u001b[39m \n\u001b[32m   1091\u001b[39m \u001b[33;03m    This method should make use of batched calls for models that expose a batched\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1120\u001b[39m \u001b[33;03m            prompt and additional model provider-specific output.\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1122\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(metadata, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_core/language_models/llms.py:803\u001b[39m, in \u001b[36mgenerate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    791\u001b[39m     output = (\n\u001b[32m    792\u001b[39m         \u001b[38;5;28mself\u001b[39m._generate(\n\u001b[32m    793\u001b[39m             prompts,\n\u001b[32m   (...)\u001b[39m\u001b[32m    800\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    801\u001b[39m     )\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m803\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[32m    804\u001b[39m         run_manager.on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_core/language_models/llms.py:670\u001b[39m, in \u001b[36m_generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    658\u001b[39m \u001b[38;5;129m@abstractmethod\u001b[39m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    660\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    664\u001b[39m     **kwargs: Any,\n\u001b[32m    665\u001b[39m ) -> LLMResult:\n\u001b[32m    666\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run the LLM on the given prompts.\"\"\"\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_agenerate\u001b[39m(\n\u001b[32m    669\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m670\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m    671\u001b[39m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    672\u001b[39m     run_manager: Optional[AsyncCallbackManagerForLLMRun] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    673\u001b[39m     **kwargs: Any,\n\u001b[32m    674\u001b[39m ) -> LLMResult:\n\u001b[32m    675\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run the LLM on the given prompts.\"\"\"\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(\n\u001b[32m    677\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    678\u001b[39m         \u001b[38;5;28mself\u001b[39m._generate,\n\u001b[32m   (...)\u001b[39m\u001b[32m    682\u001b[39m         **kwargs,\n\u001b[32m    683\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_core/language_models/llms.py:657\u001b[39m, in \u001b[36m_generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_community/llms/google_palm.py:180\u001b[39m, in \u001b[36mGooglePalm._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m     generations.append([Generation(text=c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m candidates])\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     res = \u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m     prompt_generations = []\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m candidate \u001b[38;5;129;01min\u001b[39;00m res.candidates:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_community/llms/google_palm.py:40\u001b[39m, in \u001b[36mcompletion_with_retry\u001b[39m\u001b[34m(llm, prompt, is_gemini, stream, run_manager, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m llm.client.generate_content(\n\u001b[32m     36\u001b[39m             contents=prompt, stream=stream, generation_config=generation_config\n\u001b[32m     37\u001b[39m         )\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m llm.client.generate_text(prompt=prompt, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tenacity/__init__.py:336\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    334\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    335\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tenacity/__init__.py:475\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    473\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    374\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tenacity/__init__.py:418\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    416\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tenacity/__init__.py:185\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tenacity/__init__.py:478\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    480\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_community/llms/google_palm.py:38\u001b[39m, in \u001b[36mcompletion_with_retry.<locals>._completion_with_retry\u001b[39m\u001b[34m(prompt, is_gemini, stream, **kwargs)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_gemini:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m llm.client.generate_content(\n\u001b[32m     36\u001b[39m         contents=prompt, stream=stream, generation_config=generation_config\n\u001b[32m     37\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/generativeai/text.py:200\u001b[39m, in \u001b[36mgenerate_text\u001b[39m\u001b[34m(model, prompt, temperature, candidate_count, max_output_tokens, top_p, top_k, safety_settings, stop_sequences, client)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calls the API and returns a `types.Completion` containing the response.\u001b[39;00m\n\u001b[32m    146\u001b[39m \n\u001b[32m    147\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    186\u001b[39m \u001b[33;03m    A `types.Completion` containing the model's text completion response.\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    188\u001b[39m request = _make_generate_text_request(\n\u001b[32m    189\u001b[39m     model=model,\n\u001b[32m    190\u001b[39m     prompt=prompt,\n\u001b[32m   (...)\u001b[39m\u001b[32m    197\u001b[39m     stop_sequences=stop_sequences,\n\u001b[32m    198\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/generativeai/text.py:232\u001b[39m, in \u001b[36m_generate_response\u001b[39m\u001b[34m(request, client)\u001b[39m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    230\u001b[39m     client = get_default_text_client()\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m response = \u001b[38;5;28mtype\u001b[39m(response).to_dict(response)\n\u001b[32m    235\u001b[39m response[\u001b[33m\"\u001b[39m\u001b[33mfilters\u001b[39m\u001b[33m\"\u001b[39m] = safety_types.convert_filters_to_enums(response[\u001b[33m\"\u001b[39m\u001b[33mfilters\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/text_service/client.py:915\u001b[39m, in \u001b[36mTextServiceClient.generate_text\u001b[39m\u001b[34m(self, request, model, prompt, temperature, candidate_count, max_output_tokens, top_p, top_k, retry, timeout, metadata)\u001b[39m\n\u001b[32m    912\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mNotFound\u001b[39m: 404 Requested entity was not found."
     ]
    }
   ],
   "source": [
    "# check\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.llms import GooglePalm\n",
    "\n",
    "llm = GooglePalm()\n",
    "print(llm(\"What is LangChain?\"))  # Test basic call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "710ca64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Available models:\n",
      "- models/embedding-gecko-001 (gen: ['embedText', 'countTextTokens'])\n",
      "- models/gemini-1.0-pro-vision-latest (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemini-pro-vision (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemini-1.5-pro-latest (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemini-1.5-pro-002 (gen: ['generateContent', 'countTokens', 'createCachedContent'])\n",
      "- models/gemini-1.5-pro (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemini-1.5-flash-latest (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemini-1.5-flash (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemini-1.5-flash-002 (gen: ['generateContent', 'countTokens', 'createCachedContent'])\n",
      "- models/gemini-1.5-flash-8b (gen: ['createCachedContent', 'generateContent', 'countTokens'])\n",
      "- models/gemini-1.5-flash-8b-001 (gen: ['createCachedContent', 'generateContent', 'countTokens'])\n",
      "- models/gemini-1.5-flash-8b-latest (gen: ['createCachedContent', 'generateContent', 'countTokens'])\n",
      "- models/gemini-2.5-pro-preview-03-25 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.5-flash-preview-04-17 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.5-flash-preview-05-20 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.5-flash (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.5-flash-preview-04-17-thinking (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.5-flash-lite-preview-06-17 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.5-pro-preview-05-06 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.5-pro-preview-06-05 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.5-pro (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-flash-exp (gen: ['generateContent', 'countTokens', 'bidiGenerateContent'])\n",
      "- models/gemini-2.0-flash (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-flash-001 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-flash-exp-image-generation (gen: ['generateContent', 'countTokens', 'bidiGenerateContent'])\n",
      "- models/gemini-2.0-flash-lite-001 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-flash-lite (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-flash-preview-image-generation (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemini-2.0-flash-lite-preview-02-05 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-flash-lite-preview (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-pro-exp (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-pro-exp-02-05 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-exp-1206 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-flash-thinking-exp-01-21 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-flash-thinking-exp (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.0-flash-thinking-exp-1219 (gen: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'])\n",
      "- models/gemini-2.5-flash-preview-tts (gen: ['countTokens', 'generateContent'])\n",
      "- models/gemini-2.5-pro-preview-tts (gen: ['countTokens', 'generateContent'])\n",
      "- models/learnlm-2.0-flash-experimental (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemma-3-1b-it (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemma-3-4b-it (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemma-3-12b-it (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemma-3-27b-it (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemma-3n-e4b-it (gen: ['generateContent', 'countTokens'])\n",
      "- models/gemma-3n-e2b-it (gen: ['generateContent', 'countTokens'])\n",
      "- models/embedding-001 (gen: ['embedContent'])\n",
      "- models/text-embedding-004 (gen: ['embedContent'])\n",
      "- models/gemini-embedding-exp-03-07 (gen: ['embedContent', 'countTextTokens', 'countTokens'])\n",
      "- models/gemini-embedding-exp (gen: ['embedContent', 'countTextTokens', 'countTokens'])\n",
      "- models/aqa (gen: ['generateAnswer'])\n",
      "- models/imagen-3.0-generate-002 (gen: ['predict'])\n",
      "- models/imagen-4.0-generate-preview-06-06 (gen: ['predict'])\n",
      "- models/imagen-4.0-ultra-generate-preview-06-06 (gen: ['predict'])\n",
      "- models/veo-2.0-generate-001 (gen: ['predictLongRunning'])\n",
      "- models/gemini-2.5-flash-preview-native-audio-dialog (gen: ['countTokens', 'bidiGenerateContent'])\n",
      "- models/gemini-2.5-flash-exp-native-audio-thinking-dialog (gen: ['countTokens', 'bidiGenerateContent'])\n",
      "- models/gemini-2.0-flash-live-001 (gen: ['bidiGenerateContent', 'countTokens'])\n",
      "- models/gemini-live-2.5-flash-preview (gen: ['bidiGenerateContent', 'countTokens'])\n",
      "\n",
      "‚ùå Error:\n",
      " 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n",
      "  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      "violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-1.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 46\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# If still unsure, hardcode it just for testing:\n",
    "# api_key = \"YOUR_API_KEY_HERE\"\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# List models to confirm access\n",
    "print(\"üîç Available models:\")\n",
    "for m in genai.list_models():\n",
    "    print(f\"- {m.name} (gen: {m.supported_generation_methods})\")\n",
    "\n",
    "# Try calling Gemini-Pro\n",
    "try:\n",
    "    # model = genai.GenerativeModel(\"models/gemini-pro\")  # <-- use full model path\n",
    "    \n",
    "    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\") # new code\n",
    "    response = model.generate_content(\"Explain overfitting in machine learning in 2 lines.\")\n",
    "    print(\"\\n‚úÖ Response:\\n\", response.text)\n",
    "except Exception as e:\n",
    "    print(\"\\n‚ùå Error:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24298e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.embeddings.google_palm.embed_with_retry.<locals>._embed_with_retry in 2.0 seconds as it raised NotFound: 404 Requested entity was not found..\n",
      "Retrying langchain_community.embeddings.google_palm.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised NotFound: 404 Requested entity was not found..\n",
      "Retrying langchain_community.embeddings.google_palm.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised NotFound: 404 Requested entity was not found..\n",
      "Retrying langchain_community.embeddings.google_palm.embed_with_retry.<locals>._embed_with_retry in 16.0 seconds as it raised NotFound: 404 Requested entity was not found..\n",
      "Retrying langchain_community.embeddings.google_palm.embed_with_retry.<locals>._embed_with_retry in 32.0 seconds as it raised NotFound: 404 Requested entity was not found..\n",
      "Retrying langchain_community.embeddings.google_palm.embed_with_retry.<locals>._embed_with_retry in 60.0 seconds as it raised NotFound: 404 Requested entity was not found..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mGOOGLE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mGOOGLE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m embeddings = GooglePalmEmbeddings(model_name=\u001b[33m\"\u001b[39m\u001b[33mmodels/embedding-001\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m result = \u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello world!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_community/embeddings/google_palm.py:100\u001b[39m, in \u001b[36mGooglePalmEmbeddings.embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m     99\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Embed query text.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     embedding = \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/langchain_community/embeddings/google_palm.py:52\u001b[39m, in \u001b[36membed_with_retry\u001b[39m\u001b[34m(embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_embed_with_retry\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings.client.generate_embeddings(*args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_embed_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tenacity/__init__.py:336\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    334\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    335\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tenacity/__init__.py:485\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoSleep):\n\u001b[32m    484\u001b[39m     retry_state.prepare_for_next_attempt()\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    487\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m do\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/AIDS/Projects/information-Retrieval-System/envo/lib/python3.12/site-packages/tenacity/nap.py:31\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(seconds)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msleep\u001b[39m(seconds: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import GooglePalmEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "embeddings = GooglePalmEmbeddings(model_name=\"models/embedding-001\")\n",
    "result = embeddings.embed_query(\"Hello world!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aec359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
